package Retrival
import scala.math._
import org.apache.spark.mllib.clustering.{LDA, LDAModel}

object InferenceTopics {
  def inferenceTopic(ldaModel: LDAModel, doc: String, maxIter: Int = 50): Array[Double] = {

    val topicsMatrix = normalizedTopicsMatrix(ldaModel)
    println(topicsMatrix.length + ": " + topicsMatrix(0).length)
    def hasConverged(a: Array[Double], b: Array[Double]) = {
      (a zip b).map{ case (x, y) => abs(x-y)}.max < 1e-2
    }

    val tokens = doc.split(" ").filter(!_.isEmpty).map(_.toInt)
    val prior = Array.fill(ldaModel.k)(1.0/ldaModel.k)
    val posterior = new Array[Double](ldaModel.k)
    val rangeT = 0 until ldaModel.k
    var converged = false
    var n = 0
    while(!converged && n < maxIter){
      rangeT.foreach{t => posterior(t) = 0f}
      tokens.foreach{id =>
        val z = rangeT.map{t => prior(t) * topicsMatrix(t)(id)}
        val s = z.sum
        rangeT.foreach(t => posterior(t) += z(t)/s)
      }
      val s = posterior.sum
      rangeT.foreach(t => posterior(t) /= s)
      converged = hasConverged(prior, posterior)
      rangeT.foreach(t => prior(t) = posterior(t))
      n += 1
    }
    println(s"iterated ${n} steps")
    posterior
  }


  def normalizedTopicsMatrix(ldaModel: LDAModel): Array[Array[Double]] = {
    val topics = ldaModel.describeTopics()
    val topicsMatrix = new Array[Array[Double]](ldaModel.k)
    //println(ldaModel.k)
    val rangeT = 0 until ldaModel.k
    rangeT.foreach{t => topicsMatrix(t) = (topics(t)._1 zip topics(t)._2).sortBy(_._1).map(_._2)}
    topicsMatrix
  }

}
